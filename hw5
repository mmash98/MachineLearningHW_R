# Marianna Ohanyan , ml h5 5.05.19


#install.packages("caret")
#install.packages("ggplot2")
#install.packages("e1071")
install.packages("rpart.plot")
library(caret)
library(MASS)
library(ggplot2)
library(plotROC)
library(e1071)
library(rpart.plot)



german_credit = read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data")

colnames(german_credit) = c("chk_acct", "duration", "credit_his", "purpose", 
                            "amount", "saving_acct", "present_emp", "installment_rate", "sex", "other_debtor", 
                            "present_resid", "property", "age", "other_install", "housing", "n_credits", 
                            "job", "n_people", "telephone", "foreign", "response")


# response 1 = negative 
# responce 2 = positive 



df = german_credit



# deviding data into training and testing sets 
set.seed(1)
inds <- createDataPartition(df$response, p = 0.8, list=FALSE)
#making factors for classification 
df$response = as.factor(df$response)

df_train <- df[inds,]
df_test <- df[-inds,]

summary(df)
#####1 decision tree classification 
  
grid = expand.grid(cp = seq(0, 0.4, by = 0.01))

train_control = trainControl(method = "cv",
                             number = 10)

model_tree = train(response ~ ., 
                   data = df_train, 
                   method = "rpart",
                   tuneLength = 30,
                   trControl = train_control,
                   tuneGrid = grid)

ggplot(model_tree)
#drawing tree
rpart.plot(model_tree$finalModel)
prp(model_tree$finalModel, digits = 4, roundint = F)

#confusion matrix 
model_tree_raw = predict(model_tree, newdata = df_test, type = "raw")
model_tree_prob = predict(model_tree, newdata = df_test, type = "prob")

cm1 = confusionMatrix(model_tree_raw, data = df_test$response, positive = '2')
cm1 

#Pos Pred Value : 0.4310
#Accuracy : 0.74 

#drawing roc 
roc_frame = data.frame( response = df_test$response, 
                        prob = model_tree_prob[,2] )

tt_smooth = ggplot(roc_frame, aes(m = prob, d = response)) + 
  geom_roc() + 
  coord_equal()+
  xlab("FPR") + 
  ylab("TPR")+
  ggtitle("ROC")

tt_smooth

calc_auc(tt_smooth) #0.7379189

### Instructor's comment: Show the confusion matrix and the ROC curve for the training set - ??? (-5).

#2 random forests

model_rf = train(response ~ ., 
                   data = df_train, 
                   method = "rf",
                   ntree = 50 )

#confusion matrix 
model_rf_raw = predict(model_rf, newdata = df_test, type = "raw")
model_rf_prob = predict(model_rf, newdata = df_test, type = "prob")

cm2 = confusionMatrix(model_rf_raw, data = df_test$response, positive = '2')
cm2
#Pos Pred Value : 0.3793
#Accuracy : 0.745 


roc_frame_2 = data.frame( response = df_test$response, 
                        prob = model_rf_prob[,2] )

tt_smooth2 = ggplot(roc_frame_2, aes(m = prob, d = response)) + 
  geom_roc() + 
  coord_equal()+
  xlab("FPR") + 
  ylab("TPR")+
  ggtitle("ROC")

tt_smooth2

calc_auc(tt_smooth2) ###0.7464789

### Instructor's comment: Show the confusion matrix and the ROC curve for the training set - ??? (-5).


##adaboost

model_adaboost <- train(response ~ ., 
                     data = df_train,
                     method = 'adaboost',
                     tuneGrid=expand.grid(nIter=10, method='adaboost'))


#confusion matrix 
model_boost_raw = predict(model_adaboost, newdata = df_test, type = "raw")
model_boost_prob = predict(model_adaboost, newdata = df_test, type = "prob")

cm3 = confusionMatrix(model_boost_raw, data = df_test$response, positive = '2')
cm3 

#Pos Pred Value : 0.4828 
#Accuracy : 0.73

#roc

roc_frame_3 = data.frame( response = df_test$response, 
                          prob = model_boost_prob[,2] )

tt_smooth3 = ggplot(roc_frame_3, aes(m = prob, d = response)) + 
  geom_roc() + 
  coord_equal()+
  xlab("FPR") + 
  ylab("TPR")+
  ggtitle("ROC")

tt_smooth3

calc_auc(tt_smooth3) ###0.5147523

### Instructor's comment: Show the confusion matrix and the ROC curve for the training set - ??? (-5).

###4. Compare the precisions on the test set and pick the best model for
#classification (score = 10).

#1classification tree
#Pos Pred Value(precision) : 0.4310
#Accuracy : 0.74 


#2 Random forest model:
#Pos Pred Value(precision) : 0.3793
#Accuracy : 0.745 

#3 boosting 

#Pos Pred Value(precision) : 0.4828 
#Accuracy : 0.73

#the best precison has boosting method 0.4828  





### Instructor's comment: 85/100.
